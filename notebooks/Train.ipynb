{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "* Reload modules automatically\n",
    "* Load environvent variables from .env\n",
    "* Imports\n",
    "* Load configs\n",
    "* Set up logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv\n",
    "%dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "import mlflow\n",
    "from omegaconf import OmegaConf\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = OmegaConf.load(\"../config.yaml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)\n",
    "logging.basicConfig(\n",
    "    stream=sys.stdout,\n",
    "    format=cfg.logging.format,\n",
    "    datefmt=cfg.logging.date_format,\n",
    "    level=cfg.logging.level\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_data.copy()\n",
    "y = X.pop(cfg.train.target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=cfg.train.test_size,\n",
    "    random_state=cfg.train.random_state,\n",
    "    stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    RandomForestClassifier(random_state=cfg.train.random_state, n_jobs=-1)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up experiment tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if cfg.train.experiment_name:\n",
    "    experiment = mlflow.get_experiment_by_name(name=cfg.train.experiment_name)\n",
    "    if not experiment:\n",
    "        mlflow.create_experiment(name=cfg.train.experiment_name)\n",
    "    mlflow.set_experiment(experiment_name=cfg.train.experiment_name)\n",
    "\n",
    "mlflow.autolog()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train & evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    run_info = run.info\n",
    "    logger.info(\"Running experiment with id: %s\", run_info.run_id)\n",
    "\n",
    "    logger.info(\"Fitting model.\")\n",
    "    pipeline.fit(X_train, y_train)\n",
    "\n",
    "    logger.info(\"Evaluating trained model.\")\n",
    "    model_path = mlflow.get_artifact_uri(artifact_path=\"model\")\n",
    "    test_data = X_test.copy()\n",
    "    test_data[\"target\"] = y_test\n",
    "    mlflow.evaluate(\n",
    "        model=model_path,\n",
    "        data=test_data,\n",
    "        targets=\"target\",\n",
    "        model_type=cfg.tran.model_type\n",
    "    )\n",
    "    logger.info(\"Finished experiment run %s\", run_info)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
